{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/microsoft/Phi-3-mini-128k-instruct/blob/main/sample_finetune.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig\n",
    "import torch\n",
    "import transformers\n",
    "from trl import SFTTrainer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = {\n",
    "    \"bf16\": True,\n",
    "    \"do_eval\": False,\n",
    "    \"learning_rate\": 5.0e-06,\n",
    "    \"log_level\": \"info\",\n",
    "    \"logging_steps\": 20,\n",
    "    \"logging_strategy\": \"steps\",\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"max_steps\": -1,\n",
    "    \"output_dir\": \"./checkpoint_dir\",\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"per_device_eval_batch_size\": 4,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"remove_unused_columns\": True,\n",
    "    \"save_steps\": 100,\n",
    "    \"save_total_limit\": 1,\n",
    "    \"seed\": 0,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"gradient_checkpointing_kwargs\":{\"use_reentrant\": False},\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"warmup_ratio\": 0.2,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = {\n",
    "    \"r\": 16,\n",
    "    \"lora_alpha\": 32,\n",
    "    \"lora_dropout\": 0.05,\n",
    "    \"bias\": \"none\",\n",
    "    \"task_type\": \"CAUSAL_LM\",\n",
    "    \"target_modules\": \"all-linear\",\n",
    "    \"modules_to_save\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_conf = TrainingArguments(**training_config)\n",
    "peft_conf = LoraConfig(**peft_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:23 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: False\n",
      "2024-05-17 14:39:23 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.NO,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=True,\n",
      "gradient_checkpointing_kwargs={'use_reentrant': False},\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-06,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=info,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./checkpoint_dir\\runs\\May17_14-39-23_LAPTOP-6VMJLCKR,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=20,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=SchedulerType.COSINE,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1,\n",
      "optim=OptimizerNames.ADAMW_TORCH,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=./checkpoint_dir,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./checkpoint_dir,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=100,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=0,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.2,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "2024-05-17 14:39:23 - INFO - __main__ - PEFT parameters LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='CAUSAL_LM', inference_mode=False, r=16, target_modules='all-linear', lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "log_level = train_conf.get_process_log_level()\n",
    "logger.setLevel(log_level)\n",
    "datasets.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "\n",
    "# Log on each process a small summary\n",
    "logger.warning(\n",
    "    f\"Process rank: {train_conf.local_rank}, device: {train_conf.device}, n_gpu: {train_conf.n_gpu}\"\n",
    "    + f\" distributed training: {bool(train_conf.local_rank != -1)}, 16-bits training: {train_conf.fp16}\"\n",
    ")\n",
    "logger.info(f\"Training/evaluation parameters {train_conf}\")\n",
    "logger.info(f\"PEFT parameters {peft_conf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-05-17 14:39:24,669 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\config.json\n",
      "[INFO|configuration_utils.py:726] 2024-05-17 14:39:24,899 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-17 14:39:24,900 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"microsoft/Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:25 - WARNING - transformers_modules.microsoft.Phi-3-mini-4k-instruct.8f5f3a02ec472594e949c39f8e38c7be8d983bcd.modeling_phi3 - `flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "2024-05-17 14:39:25 - WARNING - transformers_modules.microsoft.Phi-3-mini-4k-instruct.8f5f3a02ec472594e949c39f8e38c7be8d983bcd.modeling_phi3 - Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:3429] 2024-05-17 14:39:25,206 >> loading weights file model.safetensors from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1494] 2024-05-17 14:39:25,208 >> Instantiating Phi3ForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:928] 2024-05-17 14:39:25,209 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"use_cache\": false\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bf8c363f614f3387affccbdb715e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:4170] 2024-05-17 14:39:34,214 >> All model checkpoint weights were used when initializing Phi3ForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4178] 2024-05-17 14:39:34,216 >> All the weights of Phi3ForCausalLM were initialized from the model checkpoint at microsoft/Phi-3-mini-4k-instruct.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Phi3ForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:883] 2024-05-17 14:39:34,448 >> loading configuration file generation_config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\generation_config.json\n",
      "[INFO|configuration_utils.py:928] 2024-05-17 14:39:34,448 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": [\n",
      "    32000,\n",
      "    32001,\n",
      "    32007\n",
      "  ],\n",
      "  \"pad_token_id\": 32000\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2087] 2024-05-17 14:39:34,680 >> loading file tokenizer.model from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2087] 2024-05-17 14:39:34,681 >> loading file tokenizer.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2087] 2024-05-17 14:39:34,681 >> loading file added_tokens.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2087] 2024-05-17 14:39:34,681 >> loading file special_tokens_map.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2087] 2024-05-17 14:39:34,683 >> loading file tokenizer_config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\tokenizer_config.json\n",
      "[WARNING|logging.py:314] 2024-05-17 14:39:34,731 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "# Modle Loading\n",
    "################\n",
    "checkpoint_path = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "# checkpoint_path = \"microsoft/Phi-3-mini-128k-instruct\"\n",
    "model_kwargs = dict(\n",
    "    use_cache=False,\n",
    "    trust_remote_code=True,\n",
    "    #attn_implementation=\"flash_attention_2\",  # loading the model with flash-attenstion support\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=None\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint_path, **model_kwargs)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "tokenizer.model_max_length = 2048\n",
    "tokenizer.pad_token = tokenizer.unk_token  # use unk rather than eos token to prevent endless generation\n",
    "tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "tokenizer.padding_side = 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:51 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from C:\\Users\\acer alan\\.cache\\huggingface\\datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:51 - INFO - datasets.info - Loading Dataset info from C:\\Users\\acer alan\\.cache\\huggingface\\datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ultrachat_200k (C:/Users/acer alan/.cache/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:51 - INFO - datasets.builder - Found cached dataset ultrachat_200k (C:/Users/acer alan/.cache/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from C:/Users/acer alan/.cache/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:51 - INFO - datasets.info - Loading Dataset info from C:/Users/acer alan/.cache/huggingface/datasets/HuggingFaceH4___ultrachat_200k/default/0.0.0/f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# Data Processing\n",
    "##################\n",
    "def apply_chat_template(\n",
    "    example,\n",
    "    tokenizer,\n",
    "):\n",
    "    messages = example[\"messages\"]\n",
    "    # Add an empty system message if there is none\n",
    "    if messages[0][\"role\"] != \"system\":\n",
    "        messages.insert(0, {\"role\": \"system\", \"content\": \"\"})\n",
    "    example[\"text\"] = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=False)\n",
    "    return example\n",
    "\n",
    "raw_dataset = load_dataset(\"HuggingFaceH4/ultrachat_200k\")\n",
    "train_dataset = raw_dataset[\"train_sft\"]\n",
    "test_dataset = raw_dataset[\"test_sft\"]\n",
    "column_names = list(train_dataset.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #0 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-a4af82e2ea04f2ca_00000_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:51 - INFO - datasets.arrow_dataset - Process #0 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-a4af82e2ea04f2ca_00000_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #1 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-a4af82e2ea04f2ca_00001_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:51 - INFO - datasets.arrow_dataset - Process #1 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-a4af82e2ea04f2ca_00001_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #2 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-a4af82e2ea04f2ca_00002_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:51 - INFO - datasets.arrow_dataset - Process #2 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-a4af82e2ea04f2ca_00002_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #3 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-a4af82e2ea04f2ca_00003_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:51 - INFO - datasets.arrow_dataset - Process #3 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-a4af82e2ea04f2ca_00003_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #4 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-a4af82e2ea04f2ca_00004_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:51 - INFO - datasets.arrow_dataset - Process #4 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-a4af82e2ea04f2ca_00004_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #5 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-a4af82e2ea04f2ca_00005_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:51 - INFO - datasets.arrow_dataset - Process #5 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-a4af82e2ea04f2ca_00005_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #6 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-a4af82e2ea04f2ca_00006_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:51 - INFO - datasets.arrow_dataset - Process #6 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-a4af82e2ea04f2ca_00006_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #7 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-a4af82e2ea04f2ca_00007_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:51 - INFO - datasets.arrow_dataset - Process #7 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-a4af82e2ea04f2ca_00007_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #8 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-a4af82e2ea04f2ca_00008_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:51 - INFO - datasets.arrow_dataset - Process #8 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-a4af82e2ea04f2ca_00008_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #9 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-a4af82e2ea04f2ca_00009_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:51 - INFO - datasets.arrow_dataset - Process #9 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-a4af82e2ea04f2ca_00009_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-a4af82e2ea04f2ca_*_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:52 - INFO - datasets.arrow_dataset - Loading cached processed dataset at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-a4af82e2ea04f2ca_*_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Concatenating 10 shards\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:52 - INFO - datasets.arrow_dataset - Concatenating 10 shards\n"
     ]
    }
   ],
   "source": [
    "processed_train_dataset = train_dataset.map(\n",
    "    apply_chat_template,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    num_proc=10,\n",
    "    remove_columns=column_names,\n",
    "    desc=\"Applying chat template to train_sft\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #0 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-6075d1b3716be38a_00000_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:52 - INFO - datasets.arrow_dataset - Process #0 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-6075d1b3716be38a_00000_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #1 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-6075d1b3716be38a_00001_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:52 - INFO - datasets.arrow_dataset - Process #1 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-6075d1b3716be38a_00001_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #2 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-6075d1b3716be38a_00002_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:52 - INFO - datasets.arrow_dataset - Process #2 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-6075d1b3716be38a_00002_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #3 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-6075d1b3716be38a_00003_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:52 - INFO - datasets.arrow_dataset - Process #3 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-6075d1b3716be38a_00003_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #4 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-6075d1b3716be38a_00004_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:52 - INFO - datasets.arrow_dataset - Process #4 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-6075d1b3716be38a_00004_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #5 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-6075d1b3716be38a_00005_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:52 - INFO - datasets.arrow_dataset - Process #5 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-6075d1b3716be38a_00005_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #6 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-6075d1b3716be38a_00006_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:52 - INFO - datasets.arrow_dataset - Process #6 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-6075d1b3716be38a_00006_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #7 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-6075d1b3716be38a_00007_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:52 - INFO - datasets.arrow_dataset - Process #7 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-6075d1b3716be38a_00007_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #8 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-6075d1b3716be38a_00008_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:52 - INFO - datasets.arrow_dataset - Process #8 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-6075d1b3716be38a_00008_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #9 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-6075d1b3716be38a_00009_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:52 - INFO - datasets.arrow_dataset - Process #9 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-6075d1b3716be38a_00009_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-6075d1b3716be38a_*_of_00010.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:52 - INFO - datasets.arrow_dataset - Loading cached processed dataset at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\HuggingFaceH4___ultrachat_200k\\default\\0.0.0\\f8e46c0ce6e7cfa42c393cb56add1db4ea9548fb\\cache-6075d1b3716be38a_*_of_00010.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Concatenating 10 shards\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:52 - INFO - datasets.arrow_dataset - Concatenating 10 shards\n"
     ]
    }
   ],
   "source": [
    "processed_test_dataset = test_dataset.map(\n",
    "    apply_chat_template,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    num_proc=10,\n",
    "    remove_columns=column_names,\n",
    "    desc=\"Applying chat template to test_sft\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-88989bef46966697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:52 - INFO - datasets.builder - Using custom data configuration default-88989bef46966697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset Infos from c:\\Users\\acer alan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\packaged_modules\\generator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:52 - INFO - datasets.info - Loading Dataset Infos from c:\\Users\\acer alan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\packaged_modules\\generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating dataset generator (C:/Users/acer alan/.cache/huggingface/datasets/generator/default-88989bef46966697/0.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:52 - INFO - datasets.builder - Generating dataset generator (C:/Users/acer alan/.cache/huggingface/datasets/generator/default-88989bef46966697/0.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset generator/default to C:/Users/acer alan/.cache/huggingface/datasets/generator/default-88989bef46966697/0.0.0...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:52 - INFO - datasets.builder - Downloading and preparing dataset generator/default to C:/Users/acer alan/.cache/huggingface/datasets/generator/default-88989bef46966697/0.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:39:52 - INFO - datasets.builder - Generating train split\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc78111f76847e0b2c3a41cbb74a3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|tokenization_utils_base.py:3896] 2024-05-17 14:39:53,454 >> Token indices sequence length is longer than the specified maximum sequence length for this model (3588 > 2048). Running this sequence through the model will result in indexing errors\n",
      "Unable to verify splits sizes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:45:39 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset generator downloaded and prepared to C:/Users/acer alan/.cache/huggingface/datasets/generator/default-88989bef46966697/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:45:39 - INFO - datasets.builder - Dataset generator downloaded and prepared to C:/Users/acer alan/.cache/huggingface/datasets/generator/default-88989bef46966697/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-5a45937f2ee2538f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:45:39 - INFO - datasets.builder - Using custom data configuration default-5a45937f2ee2538f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset Infos from c:\\Users\\acer alan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\packaged_modules\\generator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:45:39 - INFO - datasets.info - Loading Dataset Infos from c:\\Users\\acer alan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\packaged_modules\\generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating dataset generator (C:/Users/acer alan/.cache/huggingface/datasets/generator/default-5a45937f2ee2538f/0.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:45:39 - INFO - datasets.builder - Generating dataset generator (C:/Users/acer alan/.cache/huggingface/datasets/generator/default-5a45937f2ee2538f/0.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset generator/default to C:/Users/acer alan/.cache/huggingface/datasets/generator/default-5a45937f2ee2538f/0.0.0...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:45:39 - INFO - datasets.builder - Downloading and preparing dataset generator/default to C:/Users/acer alan/.cache/huggingface/datasets/generator/default-5a45937f2ee2538f/0.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:45:39 - INFO - datasets.builder - Generating train split\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba3c5a340464a189d602d208bd11a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to verify splits sizes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:46:17 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset generator downloaded and prepared to C:/Users/acer alan/.cache/huggingface/datasets/generator/default-5a45937f2ee2538f/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:46:17 - INFO - datasets.builder - Dataset generator downloaded and prepared to C:/Users/acer alan/.cache/huggingface/datasets/generator/default-5a45937f2ee2538f/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:626] 2024-05-17 14:46:26,240 >> Using auto half precision backend\n",
      "[INFO|trainer.py:2048] 2024-05-17 14:46:26,368 >> ***** Running training *****\n",
      "[INFO|trainer.py:2049] 2024-05-17 14:46:26,369 >>   Num examples = 280,637\n",
      "[INFO|trainer.py:2050] 2024-05-17 14:46:26,369 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:2051] 2024-05-17 14:46:26,370 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:2054] 2024-05-17 14:46:26,371 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:2055] 2024-05-17 14:46:26,371 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:2056] 2024-05-17 14:46:26,372 >>   Total optimization steps = 70,160\n",
      "[INFO|trainer.py:2057] 2024-05-17 14:46:26,374 >>   Number of trainable parameters = 25,165,824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088aad9b468e4e1d980ea451b795ff7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-17 14:46:28 - WARNING - transformers_modules.microsoft.Phi-3-mini-4k-instruct.8f5f3a02ec472594e949c39f8e38c7be8d983bcd.modeling_phi3 - You are not running the flash-attention implementation, expect numerical differences.\n",
      "{'loss': 1.2806, 'grad_norm': 0.4609375, 'learning_rate': 7.126567844925884e-09, 'epoch': 0.0}\n",
      "{'loss': 1.3621, 'grad_norm': 0.4921875, 'learning_rate': 1.4253135689851768e-08, 'epoch': 0.0}\n",
      "{'loss': 1.2232, 'grad_norm': 0.63671875, 'learning_rate': 2.1379703534777654e-08, 'epoch': 0.0}\n",
      "{'loss': 1.329, 'grad_norm': 0.376953125, 'learning_rate': 2.8506271379703537e-08, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3305] 2024-05-17 14:53:06,880 >> Saving model checkpoint to ./checkpoint_dir\\checkpoint-100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3711, 'grad_norm': 0.37890625, 'learning_rate': 3.563283922462942e-08, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-05-17 14:53:08,075 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-17 14:53:08,076 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2488] 2024-05-17 14:53:08,136 >> tokenizer config file saved in ./checkpoint_dir\\checkpoint-100\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2497] 2024-05-17 14:53:08,138 >> Special tokens file saved in ./checkpoint_dir\\checkpoint-100\\special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3315, 'grad_norm': 0.44140625, 'learning_rate': 4.275940706955531e-08, 'epoch': 0.0}\n",
      "{'loss': 1.3025, 'grad_norm': 0.53125, 'learning_rate': 4.988597491448119e-08, 'epoch': 0.0}\n",
      "{'loss': 1.3158, 'grad_norm': 0.47265625, 'learning_rate': 5.701254275940707e-08, 'epoch': 0.0}\n",
      "{'loss': 1.3421, 'grad_norm': 0.53125, 'learning_rate': 6.413911060433296e-08, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3305] 2024-05-17 14:59:45,970 >> Saving model checkpoint to ./checkpoint_dir\\checkpoint-200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.288, 'grad_norm': 2.484375, 'learning_rate': 7.126567844925884e-08, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-05-17 14:59:47,084 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-17 14:59:47,085 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2488] 2024-05-17 14:59:47,137 >> tokenizer config file saved in ./checkpoint_dir\\checkpoint-200\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2497] 2024-05-17 14:59:47,139 >> Special tokens file saved in ./checkpoint_dir\\checkpoint-200\\special_tokens_map.json\n",
      "[INFO|trainer.py:3397] 2024-05-17 14:59:47,257 >> Deleting older checkpoint [checkpoint_dir\\checkpoint-100] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3619, 'grad_norm': 0.5625, 'learning_rate': 7.839224629418473e-08, 'epoch': 0.0}\n",
      "{'loss': 1.3335, 'grad_norm': 2.125, 'learning_rate': 8.551881413911062e-08, 'epoch': 0.0}\n",
      "{'loss': 1.2682, 'grad_norm': 0.380859375, 'learning_rate': 9.264538198403649e-08, 'epoch': 0.0}\n",
      "{'loss': 1.3986, 'grad_norm': 0.53125, 'learning_rate': 9.977194982896237e-08, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3305] 2024-05-17 15:06:25,919 >> Saving model checkpoint to ./checkpoint_dir\\checkpoint-300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3399, 'grad_norm': 0.6015625, 'learning_rate': 1.0689851767388827e-07, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-05-17 15:06:27,153 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-17 15:06:27,154 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2488] 2024-05-17 15:06:27,204 >> tokenizer config file saved in ./checkpoint_dir\\checkpoint-300\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2497] 2024-05-17 15:06:27,205 >> Special tokens file saved in ./checkpoint_dir\\checkpoint-300\\special_tokens_map.json\n",
      "[INFO|trainer.py:3397] 2024-05-17 15:06:27,323 >> Deleting older checkpoint [checkpoint_dir\\checkpoint-200] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3714, 'grad_norm': 0.396484375, 'learning_rate': 1.1402508551881415e-07, 'epoch': 0.0}\n",
      "{'loss': 1.2865, 'grad_norm': 0.6171875, 'learning_rate': 1.2115165336374005e-07, 'epoch': 0.0}\n",
      "{'loss': 1.2807, 'grad_norm': 0.369140625, 'learning_rate': 1.2827822120866592e-07, 'epoch': 0.01}\n",
      "{'loss': 1.3257, 'grad_norm': 0.57421875, 'learning_rate': 1.3540478905359182e-07, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3305] 2024-05-17 15:13:05,440 >> Saving model checkpoint to ./checkpoint_dir\\checkpoint-400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.342, 'grad_norm': 0.55078125, 'learning_rate': 1.425313568985177e-07, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-05-17 15:13:06,503 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-17 15:13:06,504 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2488] 2024-05-17 15:13:06,545 >> tokenizer config file saved in ./checkpoint_dir\\checkpoint-400\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2497] 2024-05-17 15:13:06,546 >> Special tokens file saved in ./checkpoint_dir\\checkpoint-400\\special_tokens_map.json\n",
      "[INFO|trainer.py:3397] 2024-05-17 15:13:06,667 >> Deleting older checkpoint [checkpoint_dir\\checkpoint-300] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2448, 'grad_norm': 0.4765625, 'learning_rate': 1.4965792474344356e-07, 'epoch': 0.01}\n",
      "{'loss': 1.3112, 'grad_norm': 1.3515625, 'learning_rate': 1.5678449258836946e-07, 'epoch': 0.01}\n",
      "{'loss': 1.3267, 'grad_norm': 0.578125, 'learning_rate': 1.6391106043329536e-07, 'epoch': 0.01}\n",
      "{'loss': 1.2542, 'grad_norm': 0.439453125, 'learning_rate': 1.7103762827822123e-07, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3305] 2024-05-17 15:19:45,130 >> Saving model checkpoint to ./checkpoint_dir\\checkpoint-500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3337, 'grad_norm': 0.52734375, 'learning_rate': 1.781641961231471e-07, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-05-17 15:19:46,221 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-17 15:19:46,222 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2488] 2024-05-17 15:19:46,263 >> tokenizer config file saved in ./checkpoint_dir\\checkpoint-500\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2497] 2024-05-17 15:19:46,264 >> Special tokens file saved in ./checkpoint_dir\\checkpoint-500\\special_tokens_map.json\n",
      "[INFO|trainer.py:3397] 2024-05-17 15:19:46,383 >> Deleting older checkpoint [checkpoint_dir\\checkpoint-400] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2873, 'grad_norm': 0.57421875, 'learning_rate': 1.8529076396807298e-07, 'epoch': 0.01}\n",
      "{'loss': 1.3042, 'grad_norm': 0.66796875, 'learning_rate': 1.9241733181299888e-07, 'epoch': 0.01}\n",
      "{'loss': 1.2938, 'grad_norm': 0.4921875, 'learning_rate': 1.9954389965792475e-07, 'epoch': 0.01}\n",
      "{'loss': 1.3039, 'grad_norm': 0.4609375, 'learning_rate': 2.0667046750285062e-07, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3305] 2024-05-17 15:26:24,768 >> Saving model checkpoint to ./checkpoint_dir\\checkpoint-600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3281, 'grad_norm': 0.41015625, 'learning_rate': 2.1379703534777655e-07, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-05-17 15:26:28,430 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-17 15:26:28,431 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2488] 2024-05-17 15:26:28,501 >> tokenizer config file saved in ./checkpoint_dir\\checkpoint-600\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2497] 2024-05-17 15:26:28,501 >> Special tokens file saved in ./checkpoint_dir\\checkpoint-600\\special_tokens_map.json\n",
      "[INFO|trainer.py:3397] 2024-05-17 15:26:28,677 >> Deleting older checkpoint [checkpoint_dir\\checkpoint-500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2627, 'grad_norm': 0.5859375, 'learning_rate': 2.2092360319270242e-07, 'epoch': 0.01}\n",
      "{'loss': 1.3081, 'grad_norm': 0.490234375, 'learning_rate': 2.280501710376283e-07, 'epoch': 0.01}\n",
      "{'loss': 1.3181, 'grad_norm': 0.494140625, 'learning_rate': 2.351767388825542e-07, 'epoch': 0.01}\n",
      "{'loss': 1.4122, 'grad_norm': 0.5546875, 'learning_rate': 2.423033067274801e-07, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3305] 2024-05-17 15:33:07,332 >> Saving model checkpoint to ./checkpoint_dir\\checkpoint-700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.259, 'grad_norm': 0.51171875, 'learning_rate': 2.4942987457240596e-07, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-05-17 15:33:08,408 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-17 15:33:08,409 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2488] 2024-05-17 15:33:08,455 >> tokenizer config file saved in ./checkpoint_dir\\checkpoint-700\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2497] 2024-05-17 15:33:08,456 >> Special tokens file saved in ./checkpoint_dir\\checkpoint-700\\special_tokens_map.json\n",
      "[INFO|trainer.py:3397] 2024-05-17 15:33:08,568 >> Deleting older checkpoint [checkpoint_dir\\checkpoint-600] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3561, 'grad_norm': 0.412109375, 'learning_rate': 2.5655644241733184e-07, 'epoch': 0.01}\n",
      "{'loss': 1.2733, 'grad_norm': 0.54296875, 'learning_rate': 2.636830102622577e-07, 'epoch': 0.01}\n",
      "{'loss': 1.2753, 'grad_norm': 0.39453125, 'learning_rate': 2.7080957810718363e-07, 'epoch': 0.01}\n",
      "{'loss': 1.3863, 'grad_norm': 0.42578125, 'learning_rate': 2.779361459521095e-07, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3305] 2024-05-17 15:39:46,740 >> Saving model checkpoint to ./checkpoint_dir\\checkpoint-800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3708, 'grad_norm': 0.490234375, 'learning_rate': 2.850627137970354e-07, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-05-17 15:39:47,787 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-17 15:39:47,788 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2488] 2024-05-17 15:39:47,839 >> tokenizer config file saved in ./checkpoint_dir\\checkpoint-800\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2497] 2024-05-17 15:39:47,840 >> Special tokens file saved in ./checkpoint_dir\\checkpoint-800\\special_tokens_map.json\n",
      "[INFO|trainer.py:3397] 2024-05-17 15:39:47,954 >> Deleting older checkpoint [checkpoint_dir\\checkpoint-700] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.317, 'grad_norm': 0.6171875, 'learning_rate': 2.9218928164196125e-07, 'epoch': 0.01}\n",
      "{'loss': 1.2991, 'grad_norm': 0.490234375, 'learning_rate': 2.993158494868871e-07, 'epoch': 0.01}\n",
      "{'loss': 1.2365, 'grad_norm': 0.45703125, 'learning_rate': 3.06442417331813e-07, 'epoch': 0.01}\n",
      "{'loss': 1.2613, 'grad_norm': 0.435546875, 'learning_rate': 3.135689851767389e-07, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3305] 2024-05-17 15:46:26,317 >> Saving model checkpoint to ./checkpoint_dir\\checkpoint-900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3155, 'grad_norm': 0.470703125, 'learning_rate': 3.206955530216648e-07, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-05-17 15:46:27,687 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-17 15:46:27,688 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2488] 2024-05-17 15:46:27,737 >> tokenizer config file saved in ./checkpoint_dir\\checkpoint-900\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2497] 2024-05-17 15:46:27,738 >> Special tokens file saved in ./checkpoint_dir\\checkpoint-900\\special_tokens_map.json\n",
      "[INFO|trainer.py:3397] 2024-05-17 15:46:27,850 >> Deleting older checkpoint [checkpoint_dir\\checkpoint-800] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3189, 'grad_norm': 0.390625, 'learning_rate': 3.278221208665907e-07, 'epoch': 0.01}\n",
      "{'loss': 1.3335, 'grad_norm': 0.5546875, 'learning_rate': 3.349486887115166e-07, 'epoch': 0.01}\n",
      "{'loss': 1.2078, 'grad_norm': 0.4921875, 'learning_rate': 3.4207525655644247e-07, 'epoch': 0.01}\n",
      "{'loss': 1.2346, 'grad_norm': 0.48828125, 'learning_rate': 3.4920182440136834e-07, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3305] 2024-05-17 15:53:06,454 >> Saving model checkpoint to ./checkpoint_dir\\checkpoint-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3288, 'grad_norm': 0.5859375, 'learning_rate': 3.563283922462942e-07, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-05-17 15:53:07,617 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-17 15:53:07,618 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2488] 2024-05-17 15:53:07,667 >> tokenizer config file saved in ./checkpoint_dir\\checkpoint-1000\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2497] 2024-05-17 15:53:07,668 >> Special tokens file saved in ./checkpoint_dir\\checkpoint-1000\\special_tokens_map.json\n",
      "[INFO|trainer.py:3397] 2024-05-17 15:53:07,781 >> Deleting older checkpoint [checkpoint_dir\\checkpoint-900] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2995, 'grad_norm': 0.40234375, 'learning_rate': 3.634549600912201e-07, 'epoch': 0.01}\n",
      "{'loss': 1.2837, 'grad_norm': 0.453125, 'learning_rate': 3.7058152793614596e-07, 'epoch': 0.01}\n",
      "{'loss': 1.2435, 'grad_norm': 0.35546875, 'learning_rate': 3.777080957810719e-07, 'epoch': 0.02}\n",
      "{'loss': 1.2545, 'grad_norm': 0.62890625, 'learning_rate': 3.8483466362599775e-07, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3305] 2024-05-17 15:59:46,036 >> Saving model checkpoint to ./checkpoint_dir\\checkpoint-1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3551, 'grad_norm': 0.546875, 'learning_rate': 3.919612314709236e-07, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-05-17 15:59:47,203 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-17 15:59:47,206 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2488] 2024-05-17 15:59:47,255 >> tokenizer config file saved in ./checkpoint_dir\\checkpoint-1100\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2497] 2024-05-17 15:59:47,256 >> Special tokens file saved in ./checkpoint_dir\\checkpoint-1100\\special_tokens_map.json\n",
      "[INFO|trainer.py:3397] 2024-05-17 15:59:47,377 >> Deleting older checkpoint [checkpoint_dir\\checkpoint-1000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2783, 'grad_norm': 0.51171875, 'learning_rate': 3.990877993158495e-07, 'epoch': 0.02}\n",
      "{'loss': 1.2753, 'grad_norm': 0.51171875, 'learning_rate': 4.0621436716077537e-07, 'epoch': 0.02}\n",
      "{'loss': 1.314, 'grad_norm': 0.578125, 'learning_rate': 4.1334093500570124e-07, 'epoch': 0.02}\n",
      "{'loss': 1.3521, 'grad_norm': 0.455078125, 'learning_rate': 4.204675028506271e-07, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3305] 2024-05-17 16:06:25,942 >> Saving model checkpoint to ./checkpoint_dir\\checkpoint-1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3057, 'grad_norm': 0.474609375, 'learning_rate': 4.275940706955531e-07, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-05-17 16:06:27,029 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-17 16:06:27,030 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2488] 2024-05-17 16:06:27,083 >> tokenizer config file saved in ./checkpoint_dir\\checkpoint-1200\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2497] 2024-05-17 16:06:27,084 >> Special tokens file saved in ./checkpoint_dir\\checkpoint-1200\\special_tokens_map.json\n",
      "[INFO|trainer.py:3397] 2024-05-17 16:06:27,196 >> Deleting older checkpoint [checkpoint_dir\\checkpoint-1100] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3644, 'grad_norm': 0.89453125, 'learning_rate': 4.3472063854047897e-07, 'epoch': 0.02}\n",
      "{'loss': 1.3178, 'grad_norm': 0.671875, 'learning_rate': 4.4184720638540484e-07, 'epoch': 0.02}\n",
      "{'loss': 1.3397, 'grad_norm': 0.47265625, 'learning_rate': 4.489737742303307e-07, 'epoch': 0.02}\n",
      "{'loss': 1.3497, 'grad_norm': 0.7265625, 'learning_rate': 4.561003420752566e-07, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3305] 2024-05-17 16:13:05,592 >> Saving model checkpoint to ./checkpoint_dir\\checkpoint-1300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3237, 'grad_norm': 0.546875, 'learning_rate': 4.632269099201825e-07, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-05-17 16:13:06,674 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-17 16:13:06,675 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2488] 2024-05-17 16:13:06,717 >> tokenizer config file saved in ./checkpoint_dir\\checkpoint-1300\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2497] 2024-05-17 16:13:06,718 >> Special tokens file saved in ./checkpoint_dir\\checkpoint-1300\\special_tokens_map.json\n",
      "[INFO|trainer.py:3397] 2024-05-17 16:13:06,834 >> Deleting older checkpoint [checkpoint_dir\\checkpoint-1200] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2832, 'grad_norm': 0.5078125, 'learning_rate': 4.703534777651084e-07, 'epoch': 0.02}\n",
      "{'loss': 1.255, 'grad_norm': 0.40234375, 'learning_rate': 4.774800456100342e-07, 'epoch': 0.02}\n",
      "{'loss': 1.3881, 'grad_norm': 0.53125, 'learning_rate': 4.846066134549602e-07, 'epoch': 0.02}\n",
      "{'loss': 1.268, 'grad_norm': 0.41015625, 'learning_rate': 4.917331812998861e-07, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3305] 2024-05-17 16:19:45,502 >> Saving model checkpoint to ./checkpoint_dir\\checkpoint-1400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3214, 'grad_norm': 0.451171875, 'learning_rate': 4.988597491448119e-07, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-05-17 16:19:47,183 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-17 16:19:47,184 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2488] 2024-05-17 16:19:47,235 >> tokenizer config file saved in ./checkpoint_dir\\checkpoint-1400\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2497] 2024-05-17 16:19:47,236 >> Special tokens file saved in ./checkpoint_dir\\checkpoint-1400\\special_tokens_map.json\n",
      "[INFO|trainer.py:3397] 2024-05-17 16:19:47,348 >> Deleting older checkpoint [checkpoint_dir\\checkpoint-1300] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1883, 'grad_norm': 2.296875, 'learning_rate': 5.059863169897378e-07, 'epoch': 0.02}\n",
      "{'loss': 1.2271, 'grad_norm': 0.44140625, 'learning_rate': 5.131128848346637e-07, 'epoch': 0.02}\n",
      "{'loss': 1.2426, 'grad_norm': 0.5234375, 'learning_rate': 5.202394526795895e-07, 'epoch': 0.02}\n",
      "{'loss': 1.3712, 'grad_norm': 0.53125, 'learning_rate': 5.273660205245154e-07, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3305] 2024-05-17 16:26:25,999 >> Saving model checkpoint to ./checkpoint_dir\\checkpoint-1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.327, 'grad_norm': 0.46484375, 'learning_rate': 5.344925883694413e-07, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-05-17 16:26:27,032 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-17 16:26:27,033 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2488] 2024-05-17 16:26:27,078 >> tokenizer config file saved in ./checkpoint_dir\\checkpoint-1500\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2497] 2024-05-17 16:26:27,078 >> Special tokens file saved in ./checkpoint_dir\\checkpoint-1500\\special_tokens_map.json\n",
      "[INFO|trainer.py:3397] 2024-05-17 16:26:27,194 >> Deleting older checkpoint [checkpoint_dir\\checkpoint-1400] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3116, 'grad_norm': 0.458984375, 'learning_rate': 5.416191562143673e-07, 'epoch': 0.02}\n",
      "{'loss': 1.3143, 'grad_norm': 0.54296875, 'learning_rate': 5.487457240592931e-07, 'epoch': 0.02}\n",
      "{'loss': 1.2597, 'grad_norm': 0.52734375, 'learning_rate': 5.55872291904219e-07, 'epoch': 0.02}\n",
      "{'loss': 1.3679, 'grad_norm': 0.4609375, 'learning_rate': 5.629988597491449e-07, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3305] 2024-05-17 16:33:05,964 >> Saving model checkpoint to ./checkpoint_dir\\checkpoint-1600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2521, 'grad_norm': 0.61328125, 'learning_rate': 5.701254275940708e-07, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-05-17 16:33:07,045 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-17 16:33:07,046 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2488] 2024-05-17 16:33:07,089 >> tokenizer config file saved in ./checkpoint_dir\\checkpoint-1600\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2497] 2024-05-17 16:33:07,090 >> Special tokens file saved in ./checkpoint_dir\\checkpoint-1600\\special_tokens_map.json\n",
      "[INFO|trainer.py:3397] 2024-05-17 16:33:07,203 >> Deleting older checkpoint [checkpoint_dir\\checkpoint-1500] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2843, 'grad_norm': 0.70703125, 'learning_rate': 5.772519954389966e-07, 'epoch': 0.02}\n",
      "{'loss': 1.291, 'grad_norm': 0.412109375, 'learning_rate': 5.843785632839225e-07, 'epoch': 0.02}\n",
      "{'loss': 1.2915, 'grad_norm': 0.60546875, 'learning_rate': 5.915051311288484e-07, 'epoch': 0.02}\n",
      "{'loss': 1.2584, 'grad_norm': 0.390625, 'learning_rate': 5.986316989737742e-07, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3305] 2024-05-17 16:39:45,585 >> Saving model checkpoint to ./checkpoint_dir\\checkpoint-1700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2831, 'grad_norm': 0.5859375, 'learning_rate': 6.057582668187001e-07, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-05-17 16:39:46,861 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-17 16:39:46,862 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2488] 2024-05-17 16:39:46,909 >> tokenizer config file saved in ./checkpoint_dir\\checkpoint-1700\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2497] 2024-05-17 16:39:46,910 >> Special tokens file saved in ./checkpoint_dir\\checkpoint-1700\\special_tokens_map.json\n",
      "[INFO|trainer.py:3397] 2024-05-17 16:39:47,026 >> Deleting older checkpoint [checkpoint_dir\\checkpoint-1600] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2688, 'grad_norm': 0.427734375, 'learning_rate': 6.12884834663626e-07, 'epoch': 0.02}\n",
      "{'loss': 1.2356, 'grad_norm': 0.40234375, 'learning_rate': 6.20011402508552e-07, 'epoch': 0.02}\n",
      "{'loss': 1.224, 'grad_norm': 0.427734375, 'learning_rate': 6.271379703534778e-07, 'epoch': 0.03}\n",
      "{'loss': 1.2477, 'grad_norm': 0.46875, 'learning_rate': 6.342645381984037e-07, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3305] 2024-05-17 16:46:25,635 >> Saving model checkpoint to ./checkpoint_dir\\checkpoint-1800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2846, 'grad_norm': 0.33203125, 'learning_rate': 6.413911060433296e-07, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-05-17 16:46:27,553 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-17 16:46:27,556 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2488] 2024-05-17 16:46:27,599 >> tokenizer config file saved in ./checkpoint_dir\\checkpoint-1800\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2497] 2024-05-17 16:46:27,600 >> Special tokens file saved in ./checkpoint_dir\\checkpoint-1800\\special_tokens_map.json\n",
      "[INFO|trainer.py:3397] 2024-05-17 16:46:27,717 >> Deleting older checkpoint [checkpoint_dir\\checkpoint-1700] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2459, 'grad_norm': 0.48046875, 'learning_rate': 6.485176738882555e-07, 'epoch': 0.03}\n",
      "{'loss': 1.2918, 'grad_norm': 0.62109375, 'learning_rate': 6.556442417331814e-07, 'epoch': 0.03}\n",
      "{'loss': 1.3562, 'grad_norm': 0.41796875, 'learning_rate': 6.627708095781073e-07, 'epoch': 0.03}\n",
      "{'loss': 1.3743, 'grad_norm': 0.404296875, 'learning_rate': 6.698973774230332e-07, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3305] 2024-05-17 16:53:06,543 >> Saving model checkpoint to ./checkpoint_dir\\checkpoint-1900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2572, 'grad_norm': 0.33984375, 'learning_rate': 6.770239452679591e-07, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-05-17 16:53:07,593 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-17 16:53:07,595 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2488] 2024-05-17 16:53:07,653 >> tokenizer config file saved in ./checkpoint_dir\\checkpoint-1900\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2497] 2024-05-17 16:53:07,654 >> Special tokens file saved in ./checkpoint_dir\\checkpoint-1900\\special_tokens_map.json\n",
      "[INFO|trainer.py:3397] 2024-05-17 16:53:07,770 >> Deleting older checkpoint [checkpoint_dir\\checkpoint-1800] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2607, 'grad_norm': 0.61328125, 'learning_rate': 6.841505131128849e-07, 'epoch': 0.03}\n",
      "{'loss': 1.2962, 'grad_norm': 0.375, 'learning_rate': 6.912770809578108e-07, 'epoch': 0.03}\n",
      "{'loss': 1.3135, 'grad_norm': 0.357421875, 'learning_rate': 6.984036488027367e-07, 'epoch': 0.03}\n",
      "{'loss': 1.338, 'grad_norm': 0.40234375, 'learning_rate': 7.055302166476625e-07, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3305] 2024-05-17 16:59:46,819 >> Saving model checkpoint to ./checkpoint_dir\\checkpoint-2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2499, 'grad_norm': 0.302734375, 'learning_rate': 7.126567844925884e-07, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-05-17 16:59:47,858 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-17 16:59:47,859 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2488] 2024-05-17 16:59:47,911 >> tokenizer config file saved in ./checkpoint_dir\\checkpoint-2000\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2497] 2024-05-17 16:59:47,913 >> Special tokens file saved in ./checkpoint_dir\\checkpoint-2000\\special_tokens_map.json\n",
      "[INFO|trainer.py:3397] 2024-05-17 16:59:48,042 >> Deleting older checkpoint [checkpoint_dir\\checkpoint-1900] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3731, 'grad_norm': 0.45703125, 'learning_rate': 7.197833523375143e-07, 'epoch': 0.03}\n",
      "{'loss': 1.2776, 'grad_norm': 0.439453125, 'learning_rate': 7.269099201824402e-07, 'epoch': 0.03}\n",
      "{'loss': 1.2815, 'grad_norm': 0.68359375, 'learning_rate': 7.34036488027366e-07, 'epoch': 0.03}\n",
      "{'loss': 1.2587, 'grad_norm': 0.400390625, 'learning_rate': 7.411630558722919e-07, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3305] 2024-05-17 17:06:27,826 >> Saving model checkpoint to ./checkpoint_dir\\checkpoint-2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1752, 'grad_norm': 0.35546875, 'learning_rate': 7.482896237172178e-07, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-05-17 17:06:28,909 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-4k-instruct\\snapshots\\8f5f3a02ec472594e949c39f8e38c7be8d983bcd\\config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-17 17:06:28,910 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 2047,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2488] 2024-05-17 17:06:28,960 >> tokenizer config file saved in ./checkpoint_dir\\checkpoint-2100\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2497] 2024-05-17 17:06:28,962 >> Special tokens file saved in ./checkpoint_dir\\checkpoint-2100\\special_tokens_map.json\n",
      "[INFO|trainer.py:3397] 2024-05-17 17:06:29,079 >> Deleting older checkpoint [checkpoint_dir\\checkpoint-2000] due to args.save_total_limit\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "# Training\n",
    "###########\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=train_conf,\n",
    "    peft_config=peft_conf,\n",
    "    train_dataset=processed_train_dataset,\n",
    "    eval_dataset=processed_test_dataset,\n",
    "    max_seq_length=1024,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    packing=True\n",
    ")\n",
    "train_result = trainer.train()\n",
    "metrics = train_result.metrics\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# Evaluation\n",
    "#############\n",
    "tokenizer.padding_side = 'left'\n",
    "metrics = trainer.evaluate()\n",
    "metrics[\"eval_samples\"] = len(processed_test_dataset)\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############\n",
    "# # Save model\n",
    "# ############\n",
    "trainer.save_model(train_conf.output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/thedeephub/optimizing-phi-2-a-deep-dive-into-fine-tuning-small-language-models-9d545ac90a99\n",
    "# https://huggingface.co/datasets/THUDM/webglm-qa/viewer/default/train?p=49&row=4904"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.1.0+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: peft in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (2.1.0+cu121)\n",
      "Requirement already satisfied: transformers in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (4.40.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (4.66.2)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (0.30.0)\n",
      "Requirement already satisfied: safetensors in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (0.4.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from peft) (0.22.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (2024.3.1)\n",
      "Requirement already satisfied: requests in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.13.0->peft) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->peft) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->peft) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers->peft) (0.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: bitsandbytes in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.43.1)\n",
      "Requirement already satisfied: torch in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bitsandbytes) (2.1.0+cu121)\n",
      "Requirement already satisfied: numpy in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bitsandbytes) (1.26.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->bitsandbytes) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->bitsandbytes) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->bitsandbytes) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->bitsandbytes) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->bitsandbytes) (2024.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch->bitsandbytes) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.40.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: trl in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.8.6)\n",
      "Requirement already satisfied: torch>=1.4.0 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trl) (2.1.0+cu121)\n",
      "Requirement already satisfied: transformers>=4.31.0 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trl) (4.40.2)\n",
      "Requirement already satisfied: numpy>=1.18.2 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trl) (1.26.3)\n",
      "Requirement already satisfied: accelerate in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trl) (0.30.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trl) (2.19.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trl) (0.8.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.4.0->trl) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.4.0->trl) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.4.0->trl) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.4.0->trl) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.4.0->trl) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.4.0->trl) (2024.3.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers>=4.31.0->trl) (0.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers>=4.31.0->trl) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers>=4.31.0->trl) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers>=4.31.0->trl) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers>=4.31.0->trl) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers>=4.31.0->trl) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers>=4.31.0->trl) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers>=4.31.0->trl) (4.66.2)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tyro>=0.5.11->trl) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
      "Requirement already satisfied: colorama>=0.4.0 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tyro>=0.5.11->trl) (0.4.6)\n",
      "Requirement already satisfied: psutil in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate->trl) (5.9.8)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets->trl) (16.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets->trl) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets->trl) (2.2.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets->trl) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets->trl) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from datasets->trl) (3.9.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets->trl) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets->trl) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets->trl) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets->trl) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->datasets->trl) (1.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers>=4.31.0->trl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers>=4.31.0->trl) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers>=4.31.0->trl) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers>=4.31.0->trl) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.17.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.4.0->trl) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets->trl) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->datasets->trl) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n",
      "Requirement already satisfied: accelerate in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.30.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (2.1.0+cu121)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: requests in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: einops in c:\\users\\acer alan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.7.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch \n",
    "!pip install peft\n",
    "!pip install bitsandbytes\n",
    "!pip install transformers\n",
    "!pip install trl \n",
    "!pip install accelerate\n",
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707c9a0a238d4a1cb37a98507dcfcafe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "#model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "model_name = \"microsoft/phi-2\"\n",
    "# Configuration to load model in 4-bit quantized\n",
    "bnb_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                                bnb_4bit_quant_type='nf4',\n",
    "                                bnb_4bit_compute_dtype='float16',\n",
    "                                #bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                                bnb_4bit_use_double_quant=True)\n",
    "\n",
    "\n",
    "#Loading Microsoft's Phi-2 model with compatible settings\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map='auto',\n",
    "                                             quantization_config=bnb_config,\n",
    "                                             attn_implementation=\"flash_attention_2\",\n",
    "                                             trust_remote_code=True)\n",
    "\n",
    "# Setting up the tokenizer for Phi-2\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
    "                                          add_eos_token=True,\n",
    "                                          trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.truncation_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer', 'references'],\n",
      "    num_rows: 5000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'references'],\n",
      "    num_rows: 1400\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "#Load a slice of the WebGLM dataset for training and merge validation/test datasets\n",
    "train_dataset = load_dataset(\"THUDM/webglm-qa\", split=\"train[5000:10000]\")\n",
    "test_dataset = load_dataset(\"THUDM/webglm-qa\", split=\"validation+test\")\n",
    "\n",
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that creates a prompt from instruction, context, category and response and tokenizes it\n",
    "def collate_and_tokenize(examples):\n",
    "\n",
    "    question = examples[\"question\"][0].replace('\"', r'\\\"')\n",
    "    answer = examples[\"answer\"][0].replace('\"', r'\\\"')\n",
    "    #unpacking the list of references and creating one string for reference\n",
    "    references = '\\n'.join([f\"[{index + 1}] {string}\" for index, string in enumerate(examples[\"references\"][0])])\n",
    "\n",
    "    #Merging into one prompt for tokenization and training\n",
    "    prompt = f\"\"\"###System:\n",
    "Read the references provided and answer the corresponding question.\n",
    "###References:\n",
    "{references}\n",
    "###Question:\n",
    "{question}\n",
    "###Answer:\n",
    "{answer}\"\"\"\n",
    "\n",
    "    #Tokenize the prompt\n",
    "    encoded = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"np\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        ## Very critical to keep max_length at 1024.\n",
    "        ## Anything more will lead to OOM on T4\n",
    "        max_length=512,\n",
    "    )\n",
    "\n",
    "    encoded[\"labels\"] = encoded[\"input_ids\"]\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df8481495e146728b2225c60ea8a609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ae4ae73fce4ebaba6fa0ac0a54d1b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#We will just keep the input_ids and labels that we add in function above.\n",
    "columns_to_remove = [\"question\",\"answer\", \"references\"]\n",
    "\n",
    "#tokenize the training and test datasets\n",
    "tokenized_dataset_train = train_dataset.map(collate_and_tokenize,\n",
    "                                            batched=True,\n",
    "                                            batch_size=1,\n",
    "                                            remove_columns=columns_to_remove)\n",
    "tokenized_dataset_test = test_dataset.map(collate_and_tokenize,\n",
    "                                          batched=True,\n",
    "                                          batch_size=1,\n",
    "                                          remove_columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###System:\n",
      "Read the references provided and answer the corresponding question.\n",
      "###References:\n",
      "[1] - Elevation/Evolution: If your mole becomes raised after being flat, or it changes over a short period of time.\n",
      "[2] There are many reasons why raised moles occur, the main one being a healthy benign intradermal mole, which can be genetic, long standing, soft and sometimes wobbly to touch. They may lose colour or get darker with age. These types of moles should be monitored for drastic change, but generally aren't cause for concern.\n",
      "[3] Moles can lighten or darken in color, and raise or flatten. Sometimes, moles can even disappear altogether.\n",
      "[4] However, moles that change and become raised could be an indication of melanoma (as pictured above), and as mentioned previously, if a mole changes, seek advice from skin cancer specialist.\n",
      "[5] Yes. In some cases, moles may lighten or completely disappear later in life. In some instances, this is the result of the body's immune system attacking the mole and causing it to regress. One example of this is a \"halo nevus.\" The presence of this phenomenon does not necessarily signal the presence of cancer. A doctor should evaluate the nevus on its own merits, exclusive of the presence of the halo.\n",
      "###Question:\n",
      "Why are some moles flat and others are raised?\n",
      "###Answer:\n",
      "Moles can be flat or raised for a variety of reasons. Flat moles are typically healthy, benign intradermal moles that are genetic, long standing, soft, and sometimes wobbly to touch[2]. They may lose colour or get darker with age. Raised moles can be caused by elevation or evolution, where the mole becomes raised after being flat or changes over a short period of time. Moles can also lighten or darken in color and even disappear altogether[3]. However, drastic changes or raised moles could be an indication of melanoma, so it’s important to seek advice from a skin cancer specialist[4]. In some cases, moles may lighten or completely disappear later in life, which could be the result of the body's immune system attacking the mole[5].\n"
     ]
    }
   ],
   "source": [
    "#Check if tokenization looks good\n",
    "input_ids = tokenized_dataset_train[1]['input_ids']\n",
    "\n",
    "decoded = tokenizer.decode(input_ids, skip_special_tokens=True)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accelerate training models on larger batch sizes, we can use a fully sharded data parallel model.\n",
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 262364160 || all params: 1521392640 || trainable%: 17.24\n",
      "PhiForCausalLM(\n",
      "  (model): PhiModel(\n",
      "    (embed_tokens): Embedding(51200, 2560)\n",
      "    (embed_dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x PhiDecoderLayer(\n",
      "        (self_attn): PhiFlashAttention2(\n",
      "          (q_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
      "          (k_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
      "          (v_proj): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
      "          (dense): Linear4bit(in_features=2560, out_features=2560, bias=True)\n",
      "          (rotary_emb): PhiRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): PhiMLP(\n",
      "          (activation_fn): NewGELUActivation()\n",
      "          (fc1): Linear4bit(in_features=2560, out_features=10240, bias=True)\n",
      "          (fc2): Linear4bit(in_features=10240, out_features=2560, bias=True)\n",
      "        )\n",
      "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2560, out_features=51200, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "print_trainable_parameters(model)\n",
    "\n",
    "#gradient checkpointing to save memory\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# Freeze base model layers and cast layernorm in fp32\n",
    "model = prepare_model_for_kbit_training(model, use_gradient_checkpointing=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 23592960 || all params: 1544985600 || trainable%: 1.53\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules= \"all-linear\", #print(model) will show the modules to use\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(model, config)\n",
    "print_trainable_parameters(lora_model)\n",
    "\n",
    "\n",
    "lora_model = accelerator.prepare_model(lora_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a3631c679442c790da4b420722e9e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9531, 'grad_norm': 0.4889421761035919, 'learning_rate': 4.736842105263158e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b57fb592dd0425fa6a5e81d54d6958a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7174506187438965, 'eval_runtime': 245.5503, 'eval_samples_per_second': 5.701, 'eval_steps_per_second': 2.851, 'epoch': 0.2}\n",
      "{'loss': 1.7244, 'grad_norm': 0.43398454785346985, 'learning_rate': 4.210526315789474e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046533ede4a84873967de5661db768b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6911202669143677, 'eval_runtime': 245.2688, 'eval_samples_per_second': 5.708, 'eval_steps_per_second': 2.854, 'epoch': 0.4}\n",
      "{'loss': 1.6893, 'grad_norm': 0.39028027653694153, 'learning_rate': 3.6842105263157895e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c980b171611b496a948327f8532ee1b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6823550462722778, 'eval_runtime': 245.194, 'eval_samples_per_second': 5.71, 'eval_steps_per_second': 2.855, 'epoch': 0.6}\n",
      "{'loss': 1.7039, 'grad_norm': 0.3969404399394989, 'learning_rate': 3.157894736842105e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b449e137760f42b99157470f7c71c174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6780908107757568, 'eval_runtime': 245.9132, 'eval_samples_per_second': 5.693, 'eval_steps_per_second': 2.847, 'epoch': 0.8}\n",
      "{'loss': 1.7154, 'grad_norm': 0.37730899453163147, 'learning_rate': 2.6315789473684212e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e6656ccdee4a6fbacc73a4d22f02bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6745108366012573, 'eval_runtime': 246.3006, 'eval_samples_per_second': 5.684, 'eval_steps_per_second': 2.842, 'epoch': 1.0}\n",
      "{'loss': 1.6769, 'grad_norm': 0.4142472743988037, 'learning_rate': 2.105263157894737e-05, 'epoch': 1.2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f3e6aaf7794c76baab5274bb0f7a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.672951340675354, 'eval_runtime': 246.2628, 'eval_samples_per_second': 5.685, 'eval_steps_per_second': 2.842, 'epoch': 1.2}\n",
      "{'loss': 1.6771, 'grad_norm': 0.46198949217796326, 'learning_rate': 1.5789473684210526e-05, 'epoch': 1.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46adffc7c5b140aab57a186ca30ffaee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6713199615478516, 'eval_runtime': 246.0648, 'eval_samples_per_second': 5.69, 'eval_steps_per_second': 2.845, 'epoch': 1.4}\n",
      "{'loss': 1.6925, 'grad_norm': 0.45856770873069763, 'learning_rate': 1.0526315789473684e-05, 'epoch': 1.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79530ca694a7412e8e13a5897637bdce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6701939105987549, 'eval_runtime': 246.0588, 'eval_samples_per_second': 5.69, 'eval_steps_per_second': 2.845, 'epoch': 1.6}\n",
      "{'loss': 1.6891, 'grad_norm': 0.43925148248672485, 'learning_rate': 5.263157894736842e-06, 'epoch': 1.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "461e7fe733d04d59954c117fd13273fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6691566705703735, 'eval_runtime': 246.0909, 'eval_samples_per_second': 5.689, 'eval_steps_per_second': 2.844, 'epoch': 1.8}\n",
      "{'loss': 1.6757, 'grad_norm': 0.4501422643661499, 'learning_rate': 0.0, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942ff7906f894e64ba26ae08131d2774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6689497232437134, 'eval_runtime': 266.1699, 'eval_samples_per_second': 5.26, 'eval_steps_per_second': 2.63, 'epoch': 2.0}\n",
      "{'train_runtime': 7899.0611, 'train_samples_per_second': 1.266, 'train_steps_per_second': 0.127, 'train_loss': 1.7197532501220703, 'epoch': 2.0}\n",
      "Training completed in 7899.168960809708 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',  # Output directory for checkpoints and predictions\n",
    "    overwrite_output_dir=True, # Overwrite the content of the output directory\n",
    "    per_device_train_batch_size=2,  # Batch size for training\n",
    "    per_device_eval_batch_size=2,  # Batch size for evaluation\n",
    "    gradient_accumulation_steps=5, # number of steps before optimizing\n",
    "    gradient_checkpointing=True,   # Enable gradient checkpointing\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "    warmup_steps=50,  # Number of warmup steps\n",
    "    #max_steps=1000,  # Total number of training steps\n",
    "    num_train_epochs=2,  # Number of training epochs\n",
    "    learning_rate=5e-5,  # Learning rate\n",
    "    weight_decay=0.01,  # Weight decay\n",
    "    optim=\"paged_adamw_8bit\", #Keep the optimizer state and quantize it\n",
    "    fp16=True, #Use mixed precision training\n",
    "    #For logging and saving\n",
    "    logging_dir='./logs',\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,  # Limit the total number of checkpoints\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    load_best_model_at_end=True, # Load the best model at the end of training\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=lora_model,\n",
    "    train_dataset=tokenized_dataset_train,\n",
    "    eval_dataset=tokenized_dataset_test,\n",
    "    args=training_args,\n",
    ")\n",
    "\n",
    "#Disable cache to prevent warning, renable for inference\n",
    "#model.config.use_cache = False\n",
    "\n",
    "start_time = time.time()  # Record the start time\n",
    "trainer.train()  # Start training\n",
    "end_time = time.time()  # Record the end time\n",
    "\n",
    "training_time = end_time - start_time  # Calculate total training time\n",
    "\n",
    "print(f\"Training completed in {training_time} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68de47ffc3bc4b478d99f7d1bd63f21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer alan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\hub.py:834: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616aed4a93d84dd5938e91e56c17b3a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/94.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/wenlianghuang/phi2-webglm-qlora-matt-test/commit/9da83c9579867953570507b9a9e92b4d5d141bc9', commit_message='Training Phi-2', commit_description='', oid='9da83c9579867953570507b9a9e92b4d5d141bc9', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save model to hub to ensure we save our work.\n",
    "lora_model.push_to_hub(\"phi2-webglm-qlora-matt-test\",\n",
    "                  use_auth_token=True,\n",
    "                  commit_message=\"Training Phi-2\",\n",
    "                  private=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prompt = \"\"\"###System:\n",
    "Read the references provided and answer the corresponding question.\n",
    "###References:\n",
    "[1] For most people, the act of reading is a reward in itself. However, studies show that reading books also has benefits that range from a longer life to career success. If you’re looking for reasons to pick up a book, read on for seven science-backed reasons why reading is good for your health, relationships and happiness.\n",
    "[2] As per a study, one of the prime benefits of reading books is slowing down mental disorders such as Alzheimer’s and Dementia  It happens since reading stimulates the brain and keeps it active, which allows it to retain its power and capacity.\n",
    "[3] Another one of the benefits of reading books is that they can improve our ability to empathize with others. And empathy has many benefits – it can reduce stress, improve our relationships, and inform our moral compasses.\n",
    "[4] Here are 10 benefits of reading that illustrate the importance of reading books. When you read every day you:\n",
    "[5] Why is reading good for you? Reading is good for you because it improves your focus, memory, empathy, and communication skills. It can reduce stress, improve your mental health, and help you live longer. Reading also allows you to learn new things to help you succeed in your work and relationships.\n",
    "###Question:\n",
    "Why is reading books widely considered to be beneficial?\n",
    "###Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['###System:\\nRead the references provided and answer the corresponding question.\\n###References:\\n[1] For most people, the act of reading is a reward in itself. However, studies show that reading books also has benefits that range from a longer life to career success. If you’re looking for reasons to pick up a book, read on for seven science-backed reasons why reading is good for your health, relationships and happiness.\\n[2] As per a study, one of the prime benefits of reading books is slowing down mental disorders such as Alzheimer’s and Dementia  It happens since reading stimulates the brain and keeps it active, which allows it to retain its power and capacity.\\n[3] Another one of the benefits of reading books is that they can improve our ability to empathize with others. And empathy has many benefits – it can reduce stress, improve our relationships, and inform our moral compasses.\\n[4] Here are 10 benefits of reading that illustrate the importance of reading books. When you read every day you:\\n[5] Why is reading good for you? Reading is good for you because it improves your focus, memory, empathy, and communication skills. It can reduce stress, improve your mental health, and help you live longer. Reading also allows you to learn new things to help you succeed in your work and relationships.\\n###Question:\\nWhy is reading books widely considered to be beneficial?\\n###Answer:\\nReading books is widely considered to be beneficial because it has many benefits that range from a longer life to career success[1]. It can slow down mental disorders such as Alzheimer’s and Dementia[2], improve our ability to empathize with others[3], and improve our focus, memory, empathy, and communication skills[5]. It can also reduce stress, improve our mental health, and help us live longer[5]. Additionally, reading allows us to learn new things to help us succeed in our work and relationships[5].']\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(new_prompt, return_tensors=\"pt\",\n",
    "                   return_attention_mask=False,\n",
    "                   padding=True, truncation=True)\n",
    "\n",
    "inputs.to('cuda')\n",
    "\n",
    "outputs = model.generate(**inputs, repetition_penalty=1.0,\n",
    "                              max_length=1000)\n",
    "result = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't find 'adapter_config.json' at 'wenlianghuang/phi2-webglm-qlora-matt-test'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\acer alan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\utils\\_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\acer alan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/wenlianghuang/phi2-webglm-qlora-matt-test/resolve/main/adapter_config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\acer alan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\peft\\config.py:197\u001b[0m, in \u001b[0;36mPeftConfigMixin._get_peft_type\u001b[1;34m(cls, model_id, **hf_hub_download_kwargs)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m     config_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhf_hub_download_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\acer alan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\acer alan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1403\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, headers, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[0;32m   1401\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[0;32m   1402\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[1;32m-> 1403\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[0;32m   1404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1405\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\acer alan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1261\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, headers, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1261\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1262\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1263\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1268\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1270\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[0;32m   1271\u001b[0m     \u001b[38;5;66;03m# Cache the non-existence of the file and raise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\acer alan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\acer alan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1674\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[0;32m   1673\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[1;32m-> 1674\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1675\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1676\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1682\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1683\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[1;32mc:\\Users\\acer alan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:369\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[1;32m--> 369\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\acer alan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:393\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    392\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m--> 393\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\acer alan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\utils\\_errors.py:352\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    344\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    345\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    346\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    351\u001b[0m     )\n\u001b[1;32m--> 352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-6659950b-6d5a7e9135fc2bc51ff0e3c8;f1540dd0-2397-4698-8ef7-65cfd9d08e25)\n\nRepository Not Found for url: https://huggingface.co/wenlianghuang/phi2-webglm-qlora-matt-test/resolve/main/adapter_config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#Load the model weights from hub\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwenlianghuang/phi2-webglm-qlora-matt-test\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mPeftModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#Run inference\u001b[39;00m\n\u001b[0;32m      8\u001b[0m outputs \u001b[38;5;241m=\u001b[39m trained_model\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\acer alan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\peft\\peft_model.py:328\u001b[0m, in \u001b[0;36mPeftModel.from_pretrained\u001b[1;34m(cls, model, model_id, adapter_name, is_trainable, config, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;66;03m# load the config\u001b[39;00m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    327\u001b[0m     config \u001b[38;5;241m=\u001b[39m PEFT_TYPE_TO_CONFIG_MAPPING[\n\u001b[1;32m--> 328\u001b[0m         \u001b[43mPeftConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_peft_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msubfolder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrevision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcache_dir\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muse_auth_token\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtoken\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    336\u001b[0m     ]\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PeftConfig):\n\u001b[0;32m    338\u001b[0m     config\u001b[38;5;241m.\u001b[39minference_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m is_trainable\n",
      "File \u001b[1;32mc:\\Users\\acer alan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\peft\\config.py:203\u001b[0m, in \u001b[0;36mPeftConfigMixin._get_peft_type\u001b[1;34m(cls, model_id, **hf_hub_download_kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m         config_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[0;32m    198\u001b[0m             model_id,\n\u001b[0;32m    199\u001b[0m             CONFIG_NAME,\n\u001b[0;32m    200\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhf_hub_download_kwargs,\n\u001b[0;32m    201\u001b[0m         )\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m--> 203\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m at \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    205\u001b[0m loaded_attributes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_json_file(config_file)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loaded_attributes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpeft_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Can't find 'adapter_config.json' at 'wenlianghuang/phi2-webglm-qlora-matt-test'"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "#Load the model weights from hub\n",
    "model_id = \"wenlianghuang/phi2-webglm-qlora-matt-test\"\n",
    "trained_model = PeftModel.from_pretrained(model, model_id)\n",
    "\n",
    "#Run inference\n",
    "outputs = trained_model.generate(**inputs, max_length=1000)\n",
    "text = tokenizer.batch_decode(outputs,skip_special_tokens=True)[0]\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

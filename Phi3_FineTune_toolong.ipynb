{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/microsoft/Phi-3-mini-128k-instruct/blob/main/sample_finetune.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig\n",
    "import torch\n",
    "import transformers\n",
    "from trl import SFTTrainer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = {\n",
    "    \"bf16\": True,\n",
    "    \"do_eval\": False,\n",
    "    \"learning_rate\": 5.0e-06,\n",
    "    \"log_level\": \"info\",\n",
    "    \"logging_steps\": 20,\n",
    "    \"logging_strategy\": \"steps\",\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"max_steps\": -1,\n",
    "    \"output_dir\": \"./checkpoint_dir\",\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"per_device_eval_batch_size\": 4,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"remove_unused_columns\": True,\n",
    "    \"save_steps\": 100,\n",
    "    \"save_total_limit\": 1,\n",
    "    \"seed\": 0,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"gradient_checkpointing_kwargs\":{\"use_reentrant\": False},\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"warmup_ratio\": 0.2,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = {\n",
    "    \"r\": 16,\n",
    "    \"lora_alpha\": 32,\n",
    "    \"lora_dropout\": 0.05,\n",
    "    \"bias\": \"none\",\n",
    "    \"task_type\": \"CAUSAL_LM\",\n",
    "    \"target_modules\": \"all-linear\",\n",
    "    \"modules_to_save\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_conf = TrainingArguments(**training_config)\n",
    "peft_conf = LoraConfig(**peft_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:39:52 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1 distributed training: True, 16-bits training: False\n",
      "2024-05-27 17:39:52 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=IntervalStrategy.NO,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=True,\n",
      "gradient_checkpointing_kwargs={'use_reentrant': False},\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-06,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=info,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./checkpoint_dir\\runs\\May27_17-39-52_LAPTOP-6VMJLCKR,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=20,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=SchedulerType.COSINE,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1,\n",
      "optim=OptimizerNames.ADAMW_TORCH,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=./checkpoint_dir,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./checkpoint_dir,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=100,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=0,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.2,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      ")\n",
      "2024-05-27 17:39:52 - INFO - __main__ - PEFT parameters LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='CAUSAL_LM', inference_mode=False, r=16, target_modules='all-linear', lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None)\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "log_level = train_conf.get_process_log_level()\n",
    "logger.setLevel(log_level)\n",
    "datasets.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "\n",
    "# Log on each process a small summary\n",
    "logger.warning(\n",
    "    f\"Process rank: {train_conf.local_rank}, device: {train_conf.device}, n_gpu: {train_conf.n_gpu}\"\n",
    "    + f\" distributed training: {bool(train_conf.local_rank != -1)}, 16-bits training: {train_conf.fp16}\"\n",
    ")\n",
    "logger.info(f\"Training/evaluation parameters {train_conf}\")\n",
    "logger.info(f\"PEFT parameters {peft_conf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-05-27 17:39:53,500 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-128k-instruct\\snapshots\\bbd531db4632bb631b0c44d98172894a0c594dd0\\config.json\n",
      "[INFO|configuration_utils.py:726] 2024-05-27 17:39:53,737 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-128k-instruct\\snapshots\\bbd531db4632bb631b0c44d98172894a0c594dd0\\config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-27 17:39:53,739 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"microsoft/Phi-3-mini-128k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-128k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-128k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"long_factor\": [\n",
      "      1.0299999713897705,\n",
      "      1.0499999523162842,\n",
      "      1.0499999523162842,\n",
      "      1.0799999237060547,\n",
      "      1.2299998998641968,\n",
      "      1.2299998998641968,\n",
      "      1.2999999523162842,\n",
      "      1.4499999284744263,\n",
      "      1.5999999046325684,\n",
      "      1.6499998569488525,\n",
      "      1.8999998569488525,\n",
      "      2.859999895095825,\n",
      "      3.68999981880188,\n",
      "      5.419999599456787,\n",
      "      5.489999771118164,\n",
      "      5.489999771118164,\n",
      "      9.09000015258789,\n",
      "      11.579999923706055,\n",
      "      15.65999984741211,\n",
      "      15.769999504089355,\n",
      "      15.789999961853027,\n",
      "      18.360000610351562,\n",
      "      21.989999771118164,\n",
      "      23.079999923706055,\n",
      "      30.009998321533203,\n",
      "      32.35000228881836,\n",
      "      32.590003967285156,\n",
      "      35.56000518798828,\n",
      "      39.95000457763672,\n",
      "      53.840003967285156,\n",
      "      56.20000457763672,\n",
      "      57.95000457763672,\n",
      "      59.29000473022461,\n",
      "      59.77000427246094,\n",
      "      59.920005798339844,\n",
      "      61.190006256103516,\n",
      "      61.96000671386719,\n",
      "      62.50000762939453,\n",
      "      63.3700065612793,\n",
      "      63.48000717163086,\n",
      "      63.48000717163086,\n",
      "      63.66000747680664,\n",
      "      63.850006103515625,\n",
      "      64.08000946044922,\n",
      "      64.760009765625,\n",
      "      64.80001068115234,\n",
      "      64.81001281738281,\n",
      "      64.81001281738281\n",
      "    ],\n",
      "    \"short_factor\": [\n",
      "      1.05,\n",
      "      1.05,\n",
      "      1.05,\n",
      "      1.1,\n",
      "      1.1,\n",
      "      1.1500000000000001,\n",
      "      1.2000000000000002,\n",
      "      1.2500000000000002,\n",
      "      1.3000000000000003,\n",
      "      1.3500000000000003,\n",
      "      1.5000000000000004,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.0500000000000007,\n",
      "      2.0500000000000007,\n",
      "      2.0500000000000007,\n",
      "      2.1000000000000005,\n",
      "      2.1000000000000005,\n",
      "      2.1000000000000005,\n",
      "      2.1500000000000004,\n",
      "      2.1500000000000004,\n",
      "      2.3499999999999996,\n",
      "      2.549999999999999,\n",
      "      2.5999999999999988,\n",
      "      2.5999999999999988,\n",
      "      2.7499999999999982,\n",
      "      2.849999999999998,\n",
      "      2.849999999999998,\n",
      "      2.9499999999999975\n",
      "    ],\n",
      "    \"type\": \"su\"\n",
      "  },\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 262144,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": false,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:39:54 - WARNING - transformers_modules.microsoft.Phi-3-mini-128k-instruct.bbd531db4632bb631b0c44d98172894a0c594dd0.modeling_phi3 - `flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "2024-05-27 17:39:54 - WARNING - transformers_modules.microsoft.Phi-3-mini-128k-instruct.bbd531db4632bb631b0c44d98172894a0c594dd0.modeling_phi3 - Current `flash-attenton` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:3429] 2024-05-27 17:39:54,036 >> loading weights file model.safetensors from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-128k-instruct\\snapshots\\bbd531db4632bb631b0c44d98172894a0c594dd0\\model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1494] 2024-05-27 17:39:54,040 >> Instantiating Phi3ForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:928] 2024-05-27 17:39:54,040 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"use_cache\": false\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12cd3c59a6d4c27b97d3084cf0651b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:4170] 2024-05-27 17:40:04,084 >> All model checkpoint weights were used when initializing Phi3ForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4178] 2024-05-27 17:40:04,087 >> All the weights of Phi3ForCausalLM were initialized from the model checkpoint at microsoft/Phi-3-mini-128k-instruct.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Phi3ForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:883] 2024-05-27 17:40:04,341 >> loading configuration file generation_config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-128k-instruct\\snapshots\\bbd531db4632bb631b0c44d98172894a0c594dd0\\generation_config.json\n",
      "[INFO|configuration_utils.py:928] 2024-05-27 17:40:04,342 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": [\n",
      "    32000,\n",
      "    32001,\n",
      "    32007\n",
      "  ],\n",
      "  \"pad_token_id\": 32000\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2087] 2024-05-27 17:40:04,626 >> loading file tokenizer.model from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-128k-instruct\\snapshots\\bbd531db4632bb631b0c44d98172894a0c594dd0\\tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2087] 2024-05-27 17:40:04,626 >> loading file tokenizer.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-128k-instruct\\snapshots\\bbd531db4632bb631b0c44d98172894a0c594dd0\\tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2087] 2024-05-27 17:40:04,627 >> loading file added_tokens.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-128k-instruct\\snapshots\\bbd531db4632bb631b0c44d98172894a0c594dd0\\added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2087] 2024-05-27 17:40:04,627 >> loading file special_tokens_map.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-128k-instruct\\snapshots\\bbd531db4632bb631b0c44d98172894a0c594dd0\\special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2087] 2024-05-27 17:40:04,627 >> loading file tokenizer_config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-128k-instruct\\snapshots\\bbd531db4632bb631b0c44d98172894a0c594dd0\\tokenizer_config.json\n",
      "[WARNING|logging.py:314] 2024-05-27 17:40:04,687 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "# Modle Loading\n",
    "################\n",
    "#checkpoint_path = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "checkpoint_path = \"microsoft/Phi-3-mini-128k-instruct\"\n",
    "model_kwargs = dict(\n",
    "    use_cache=False,\n",
    "    trust_remote_code=True,\n",
    "    #attn_implementation=\"flash_attention_2\",  # loading the model with flash-attenstion support\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=None\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint_path, **model_kwargs)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "tokenizer.model_max_length = 512\n",
    "tokenizer.pad_token = tokenizer.unk_token  # use unk rather than eos token to prevent endless generation\n",
    "tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "tokenizer.padding_side = 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from C:\\Users\\acer alan\\.cache\\huggingface\\datasets/wenlianghuang___dataset_phi3_matt_testing/default/0.0.0/a1fb0788e4ae946b0027f6f1318161a2c26c4282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.info - Loading Dataset info from C:\\Users\\acer alan\\.cache\\huggingface\\datasets/wenlianghuang___dataset_phi3_matt_testing/default/0.0.0/a1fb0788e4ae946b0027f6f1318161a2c26c4282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset dataset_phi3_matt_testing (C:/Users/acer alan/.cache/huggingface/datasets/wenlianghuang___dataset_phi3_matt_testing/default/0.0.0/a1fb0788e4ae946b0027f6f1318161a2c26c4282)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.builder - Found cached dataset dataset_phi3_matt_testing (C:/Users/acer alan/.cache/huggingface/datasets/wenlianghuang___dataset_phi3_matt_testing/default/0.0.0/a1fb0788e4ae946b0027f6f1318161a2c26c4282)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from C:/Users/acer alan/.cache/huggingface/datasets/wenlianghuang___dataset_phi3_matt_testing/default/0.0.0/a1fb0788e4ae946b0027f6f1318161a2c26c4282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.info - Loading Dataset info from C:/Users/acer alan/.cache/huggingface/datasets/wenlianghuang___dataset_phi3_matt_testing/default/0.0.0/a1fb0788e4ae946b0027f6f1318161a2c26c4282\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "# Data Processing\n",
    "##################\n",
    "def apply_chat_template(\n",
    "    example,\n",
    "    tokenizer,\n",
    "):\n",
    "    messages = example[\"messages\"]\n",
    "    # Add an empty system message if there is none\n",
    "    if messages[0][\"role\"] != \"system\":\n",
    "        messages.insert(0, {\"role\": \"system\", \"content\": \"\"})\n",
    "    example[\"text\"] = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=False)\n",
    "    return example\n",
    "\n",
    "raw_dataset = load_dataset(\"wenlianghuang/dataset_phi3_matt_testing\")\n",
    "train_dataset = raw_dataset[\"train_sft\"]\n",
    "test_dataset = raw_dataset[\"test_sft\"]\n",
    "column_names = list(train_dataset.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #0 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\wenlianghuang___dataset_phi3_matt_testing\\default\\0.0.0\\a1fb0788e4ae946b0027f6f1318161a2c26c4282\\cache-5e34ca905062940d_00000_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.arrow_dataset - Process #0 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\wenlianghuang___dataset_phi3_matt_testing\\default\\0.0.0\\a1fb0788e4ae946b0027f6f1318161a2c26c4282\\cache-5e34ca905062940d_00000_of_00005.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #1 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\wenlianghuang___dataset_phi3_matt_testing\\default\\0.0.0\\a1fb0788e4ae946b0027f6f1318161a2c26c4282\\cache-5e34ca905062940d_00001_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.arrow_dataset - Process #1 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\wenlianghuang___dataset_phi3_matt_testing\\default\\0.0.0\\a1fb0788e4ae946b0027f6f1318161a2c26c4282\\cache-5e34ca905062940d_00001_of_00005.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #2 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\wenlianghuang___dataset_phi3_matt_testing\\default\\0.0.0\\a1fb0788e4ae946b0027f6f1318161a2c26c4282\\cache-5e34ca905062940d_00002_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.arrow_dataset - Process #2 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\wenlianghuang___dataset_phi3_matt_testing\\default\\0.0.0\\a1fb0788e4ae946b0027f6f1318161a2c26c4282\\cache-5e34ca905062940d_00002_of_00005.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #3 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\wenlianghuang___dataset_phi3_matt_testing\\default\\0.0.0\\a1fb0788e4ae946b0027f6f1318161a2c26c4282\\cache-5e34ca905062940d_00003_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.arrow_dataset - Process #3 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\wenlianghuang___dataset_phi3_matt_testing\\default\\0.0.0\\a1fb0788e4ae946b0027f6f1318161a2c26c4282\\cache-5e34ca905062940d_00003_of_00005.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #4 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\wenlianghuang___dataset_phi3_matt_testing\\default\\0.0.0\\a1fb0788e4ae946b0027f6f1318161a2c26c4282\\cache-5e34ca905062940d_00004_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.arrow_dataset - Process #4 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\wenlianghuang___dataset_phi3_matt_testing\\default\\0.0.0\\a1fb0788e4ae946b0027f6f1318161a2c26c4282\\cache-5e34ca905062940d_00004_of_00005.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\wenlianghuang___dataset_phi3_matt_testing\\default\\0.0.0\\a1fb0788e4ae946b0027f6f1318161a2c26c4282\\cache-5e34ca905062940d_*_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.arrow_dataset - Loading cached processed dataset at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\wenlianghuang___dataset_phi3_matt_testing\\default\\0.0.0\\a1fb0788e4ae946b0027f6f1318161a2c26c4282\\cache-5e34ca905062940d_*_of_00005.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Concatenating 5 shards\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.arrow_dataset - Concatenating 5 shards\n"
     ]
    }
   ],
   "source": [
    "processed_train_dataset = train_dataset.map(\n",
    "    apply_chat_template,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    num_proc=5,\n",
    "    remove_columns=column_names,\n",
    "    desc=\"Applying chat template to train_sft\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #0 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\wenlianghuang___dataset_phi3_matt_testing\\default\\0.0.0\\a1fb0788e4ae946b0027f6f1318161a2c26c4282\\cache-8326648afb7f90cd_00000_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.arrow_dataset - Process #0 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\wenlianghuang___dataset_phi3_matt_testing\\default\\0.0.0\\a1fb0788e4ae946b0027f6f1318161a2c26c4282\\cache-8326648afb7f90cd_00000_of_00005.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #1 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\wenlianghuang___dataset_phi3_matt_testing\\default\\0.0.0\\a1fb0788e4ae946b0027f6f1318161a2c26c4282\\cache-8326648afb7f90cd_00001_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.arrow_dataset - Process #1 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\wenlianghuang___dataset_phi3_matt_testing\\default\\0.0.0\\a1fb0788e4ae946b0027f6f1318161a2c26c4282\\cache-8326648afb7f90cd_00001_of_00005.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #2 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\wenlianghuang___dataset_phi3_matt_testing\\default\\0.0.0\\a1fb0788e4ae946b0027f6f1318161a2c26c4282\\cache-8326648afb7f90cd_00002_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.arrow_dataset - Process #2 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\wenlianghuang___dataset_phi3_matt_testing\\default\\0.0.0\\a1fb0788e4ae946b0027f6f1318161a2c26c4282\\cache-8326648afb7f90cd_00002_of_00005.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #3 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\wenlianghuang___dataset_phi3_matt_testing\\default\\0.0.0\\a1fb0788e4ae946b0027f6f1318161a2c26c4282\\cache-8326648afb7f90cd_00003_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.arrow_dataset - Process #3 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\wenlianghuang___dataset_phi3_matt_testing\\default\\0.0.0\\a1fb0788e4ae946b0027f6f1318161a2c26c4282\\cache-8326648afb7f90cd_00003_of_00005.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process #4 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\wenlianghuang___dataset_phi3_matt_testing\\default\\0.0.0\\a1fb0788e4ae946b0027f6f1318161a2c26c4282\\cache-8326648afb7f90cd_00004_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.arrow_dataset - Process #4 will write at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\wenlianghuang___dataset_phi3_matt_testing\\default\\0.0.0\\a1fb0788e4ae946b0027f6f1318161a2c26c4282\\cache-8326648afb7f90cd_00004_of_00005.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\wenlianghuang___dataset_phi3_matt_testing\\default\\0.0.0\\a1fb0788e4ae946b0027f6f1318161a2c26c4282\\cache-8326648afb7f90cd_*_of_00005.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.arrow_dataset - Loading cached processed dataset at C:\\Users\\acer alan\\.cache\\huggingface\\datasets\\wenlianghuang___dataset_phi3_matt_testing\\default\\0.0.0\\a1fb0788e4ae946b0027f6f1318161a2c26c4282\\cache-8326648afb7f90cd_*_of_00005.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Concatenating 5 shards\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.arrow_dataset - Concatenating 5 shards\n"
     ]
    }
   ],
   "source": [
    "processed_test_dataset = test_dataset.map(\n",
    "    apply_chat_template,\n",
    "    fn_kwargs={\"tokenizer\": tokenizer},\n",
    "    num_proc=5,\n",
    "    remove_columns=column_names,\n",
    "    desc=\"Applying chat template to test_sft\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-dc18b444099791db\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.builder - Using custom data configuration default-dc18b444099791db\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset Infos from c:\\Users\\acer alan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\packaged_modules\\generator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.info - Loading Dataset Infos from c:\\Users\\acer alan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\packaged_modules\\generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from C:\\Users\\acer alan\\.cache\\huggingface\\datasets/generator/default-dc18b444099791db/0.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.info - Loading Dataset info from C:\\Users\\acer alan\\.cache\\huggingface\\datasets/generator/default-dc18b444099791db/0.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset generator (C:/Users/acer alan/.cache/huggingface/datasets/generator/default-dc18b444099791db/0.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.builder - Found cached dataset generator (C:/Users/acer alan/.cache/huggingface/datasets/generator/default-dc18b444099791db/0.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from C:/Users/acer alan/.cache/huggingface/datasets/generator/default-dc18b444099791db/0.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.info - Loading Dataset info from C:/Users/acer alan/.cache/huggingface/datasets/generator/default-dc18b444099791db/0.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-7fe346cfdf9f1dcc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.builder - Using custom data configuration default-7fe346cfdf9f1dcc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset Infos from c:\\Users\\acer alan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\packaged_modules\\generator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.info - Loading Dataset Infos from c:\\Users\\acer alan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\packaged_modules\\generator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from C:\\Users\\acer alan\\.cache\\huggingface\\datasets/generator/default-7fe346cfdf9f1dcc/0.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.info - Loading Dataset info from C:\\Users\\acer alan\\.cache\\huggingface\\datasets/generator/default-7fe346cfdf9f1dcc/0.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset generator (C:/Users/acer alan/.cache/huggingface/datasets/generator/default-7fe346cfdf9f1dcc/0.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.builder - Found cached dataset generator (C:/Users/acer alan/.cache/huggingface/datasets/generator/default-7fe346cfdf9f1dcc/0.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from C:/Users/acer alan/.cache/huggingface/datasets/generator/default-7fe346cfdf9f1dcc/0.0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:13 - INFO - datasets.info - Loading Dataset info from C:/Users/acer alan/.cache/huggingface/datasets/generator/default-7fe346cfdf9f1dcc/0.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:626] 2024-05-27 17:40:21,285 >> Using auto half precision backend\n",
      "[INFO|trainer.py:2048] 2024-05-27 17:40:21,395 >> ***** Running training *****\n",
      "[INFO|trainer.py:2049] 2024-05-27 17:40:21,396 >>   Num examples = 6,706\n",
      "[INFO|trainer.py:2050] 2024-05-27 17:40:21,396 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:2051] 2024-05-27 17:40:21,396 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:2054] 2024-05-27 17:40:21,397 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:2055] 2024-05-27 17:40:21,397 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:2056] 2024-05-27 17:40:21,398 >>   Total optimization steps = 1,677\n",
      "[INFO|trainer.py:2057] 2024-05-27 17:40:21,400 >>   Number of trainable parameters = 25,165,824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ef491bfc224632972ec914df266ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1677 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-27 17:40:21 - WARNING - transformers_modules.microsoft.Phi-3-mini-128k-instruct.bbd531db4632bb631b0c44d98172894a0c594dd0.modeling_phi3 - You are not running the flash-attention implementation, expect numerical differences.\n",
      "{'loss': 1.3124, 'grad_norm': 0.546875, 'learning_rate': 2.9761904761904765e-07, 'epoch': 0.01}\n",
      "{'loss': 1.2899, 'grad_norm': 0.68359375, 'learning_rate': 5.952380952380953e-07, 'epoch': 0.02}\n",
      "{'loss': 1.3202, 'grad_norm': 0.69140625, 'learning_rate': 8.928571428571429e-07, 'epoch': 0.04}\n",
      "{'loss': 1.2294, 'grad_norm': 0.5078125, 'learning_rate': 1.1904761904761906e-06, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:3305] 2024-05-27 17:47:31,067 >> Saving model checkpoint to ./checkpoint_dir\\checkpoint-100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3516, 'grad_norm': 0.71484375, 'learning_rate': 1.4880952380952381e-06, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:726] 2024-05-27 17:47:32,729 >> loading configuration file config.json from cache at C:\\Users\\acer alan\\.cache\\huggingface\\hub\\models--microsoft--Phi-3-mini-128k-instruct\\snapshots\\bbd531db4632bb631b0c44d98172894a0c594dd0\\config.json\n",
      "[INFO|configuration_utils.py:789] 2024-05-27 17:47:32,730 >> Model config Phi3Config {\n",
      "  \"_name_or_path\": \"Phi-3-mini-128k-instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Phi3ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"microsoft/Phi-3-mini-128k-instruct--configuration_phi3.Phi3Config\",\n",
      "    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-128k-instruct--modeling_phi3.Phi3ForCausalLM\"\n",
      "  },\n",
      "  \"bos_token_id\": 1,\n",
      "  \"embd_pdrop\": 0.0,\n",
      "  \"eos_token_id\": 32000,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"model_type\": \"phi3\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"original_max_position_embeddings\": 4096,\n",
      "  \"pad_token_id\": 32000,\n",
      "  \"resid_pdrop\": 0.0,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"long_factor\": [\n",
      "      1.0299999713897705,\n",
      "      1.0499999523162842,\n",
      "      1.0499999523162842,\n",
      "      1.0799999237060547,\n",
      "      1.2299998998641968,\n",
      "      1.2299998998641968,\n",
      "      1.2999999523162842,\n",
      "      1.4499999284744263,\n",
      "      1.5999999046325684,\n",
      "      1.6499998569488525,\n",
      "      1.8999998569488525,\n",
      "      2.859999895095825,\n",
      "      3.68999981880188,\n",
      "      5.419999599456787,\n",
      "      5.489999771118164,\n",
      "      5.489999771118164,\n",
      "      9.09000015258789,\n",
      "      11.579999923706055,\n",
      "      15.65999984741211,\n",
      "      15.769999504089355,\n",
      "      15.789999961853027,\n",
      "      18.360000610351562,\n",
      "      21.989999771118164,\n",
      "      23.079999923706055,\n",
      "      30.009998321533203,\n",
      "      32.35000228881836,\n",
      "      32.590003967285156,\n",
      "      35.56000518798828,\n",
      "      39.95000457763672,\n",
      "      53.840003967285156,\n",
      "      56.20000457763672,\n",
      "      57.95000457763672,\n",
      "      59.29000473022461,\n",
      "      59.77000427246094,\n",
      "      59.920005798339844,\n",
      "      61.190006256103516,\n",
      "      61.96000671386719,\n",
      "      62.50000762939453,\n",
      "      63.3700065612793,\n",
      "      63.48000717163086,\n",
      "      63.48000717163086,\n",
      "      63.66000747680664,\n",
      "      63.850006103515625,\n",
      "      64.08000946044922,\n",
      "      64.760009765625,\n",
      "      64.80001068115234,\n",
      "      64.81001281738281,\n",
      "      64.81001281738281\n",
      "    ],\n",
      "    \"short_factor\": [\n",
      "      1.05,\n",
      "      1.05,\n",
      "      1.05,\n",
      "      1.1,\n",
      "      1.1,\n",
      "      1.1500000000000001,\n",
      "      1.2000000000000002,\n",
      "      1.2500000000000002,\n",
      "      1.3000000000000003,\n",
      "      1.3500000000000003,\n",
      "      1.5000000000000004,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.000000000000001,\n",
      "      2.0500000000000007,\n",
      "      2.0500000000000007,\n",
      "      2.0500000000000007,\n",
      "      2.1000000000000005,\n",
      "      2.1000000000000005,\n",
      "      2.1000000000000005,\n",
      "      2.1500000000000004,\n",
      "      2.1500000000000004,\n",
      "      2.3499999999999996,\n",
      "      2.549999999999999,\n",
      "      2.5999999999999988,\n",
      "      2.5999999999999988,\n",
      "      2.7499999999999982,\n",
      "      2.849999999999998,\n",
      "      2.849999999999998,\n",
      "      2.9499999999999975\n",
      "    ],\n",
      "    \"type\": \"su\"\n",
      "  },\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 262144,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2488] 2024-05-27 17:47:32,797 >> tokenizer config file saved in ./checkpoint_dir\\checkpoint-100\\tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2497] 2024-05-27 17:47:32,798 >> Special tokens file saved in ./checkpoint_dir\\checkpoint-100\\special_tokens_map.json\n",
      "[INFO|trainer.py:3397] 2024-05-27 17:47:32,947 >> Deleting older checkpoint [checkpoint_dir\\checkpoint-100] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3087, 'grad_norm': 0.40625, 'learning_rate': 1.7857142857142859e-06, 'epoch': 0.07}\n",
      "{'loss': 1.2978, 'grad_norm': 0.421875, 'learning_rate': 2.0833333333333334e-06, 'epoch': 0.08}\n",
      "{'loss': 1.2707, 'grad_norm': 0.431640625, 'learning_rate': 2.380952380952381e-06, 'epoch': 0.1}\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "# Training\n",
    "###########\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=train_conf,\n",
    "    peft_config=peft_conf,\n",
    "    train_dataset=processed_train_dataset,\n",
    "    eval_dataset=processed_test_dataset,\n",
    "    max_seq_length=1024,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    packing=True\n",
    ")\n",
    "train_result = trainer.train()\n",
    "metrics = train_result.metrics\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# Evaluation\n",
    "#############\n",
    "tokenizer.padding_side = 'left'\n",
    "metrics = trainer.evaluate()\n",
    "metrics[\"eval_samples\"] = len(processed_test_dataset)\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############\n",
    "# # Save model\n",
    "# ############\n",
    "trainer.save_model(train_conf.output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
